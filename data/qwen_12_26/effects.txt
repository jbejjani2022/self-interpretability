12/26/25
qwen2.5-7b-instruct_instilled_weight_reports.csv
qwen2.5-7b-instruct_instilled_latent_weight_reports.csv
are copied over from the gpt4o counterparts, because they were empty
somehow, the preference fine-tuning broke the model's ability to report on weights in the expected JSON structures

> source("~/Projects/self-interpretability/qwen_effects.R", echo = TRUE)

> # `Groundhog` will load the versions of the `R` packages used for the
> # reported analyses. However, it cannot control the version of `R` that you  .... [TRUNCATED] 

> pkgs <- c("tidyverse", "brms", "bayestestR", "emmeans")

> groundhog.library(pkgs, "2025-01-15")
All requested packages are already attached

> # If you don't want to use `groundhog` or have issues with it, comment out the
> # code above and run the following code instead. Note that you will .... [TRUNCATED] 

> base_models <- c(
+   "qwen2.5-7b-instruct"
+ )

> # base_models <- c(
> #   "gpt-4o-mini-2024-07-18",
> #   "gpt-4o-2024-08-06"
> # )
> 
> instilled_parameters <-
+   read_csv("data/instilled_weight ..." ... [TRUNCATED] 
Rows: 1100 Columns: 6                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): attr1, attr2, attr3, attr4, attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> # Load the results of the regressions validating that the preferences were learned.
> instilled_regression_results <-
+   map_dfr(base_models, funct .... [TRUNCATED] 
Rows: 100 Columns: 6                                                                                   
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): b_attr1, b_attr2, b_attr3, b_attr4, b_attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> # Verify that the preferences were learned.
> learned_cors <-
+   instilled_regression_results %>%
+   left_join(instilled_parameters) %>%
+   group .... [TRUNCATED] 
Joining with `by = join_by(scenario, attr)`

> learned_cors
# A tibble: 1 × 2
  base_model             cor
  <chr>                <dbl>
1 qwen2.5-7b-instruct 0.0649

> # Load and tidy the models' introspective reports.
> weight_reports <-
+   bind_rows(
+     map_dfr(base_models, ~ read_csv(str_glue("data/qwen/{.x} ..." ... [TRUNCATED] 
Rows: 915 Columns: 18                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 1000 Columns: 18                                                                                 
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 478 Columns: 18                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 480 Columns: 18                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 966 Columns: 18                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 971 Columns: 18                                                                                  
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_at...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> weight_reports_long <-
+   weight_reports %>%
+   rename(model = explaining_model) %>%
+   select(model, scenario, version, starts_with("report")) % .... [TRUNCATED] 

> mean_reports <-
+   weight_reports_long %>%
+   group_by(model, version, scenario, attr) %>%
+   summarise(mean_report = mean(report)) %>%
+   ungro .... [TRUNCATED] 
`summarise()` has grouped output by 'model', 'version', 'scenario'. You can override using the
`.groups` argument.

> # Check the accuracy of model reports (without training).
> instilled_reports_data <-
+   mean_reports %>%
+   filter(version == "instilled_100") %> .... [TRUNCATED] 
Joining with `by = join_by(scenario, attr, base_model)`

> instilled_reports_data %>%
+   count(model, sort = TRUE) %>%
+   print(n = 50)
# A tibble: 4 × 2
  model                                                 n
  <chr>                                             <int>
1 qwen2.5-7b-instruct:100-instilled-prefs-50ex        500
2 qwen2.5-7b-instruct                                 475
3 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex   245
4 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex    245

> instilled_reports_data %>%
+   distinct(model) %>%
+   print(n = 50)
# A tibble: 4 × 1
  model                                            
  <chr>                                            
1 qwen2.5-7b-instruct                              
2 qwen2.5-7b-instruct:100-instilled-prefs-50ex     
3 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex
4 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex 

> inst_models_inst_reports <-
+   instilled_reports_data %>%
+   filter(str_detect(model, "instilled"))

> instilled_reports_data %>% count(model, sort = TRUE) %>% print(n = 50)
# A tibble: 4 × 2
  model                                                 n
  <chr>                                             <int>
1 qwen2.5-7b-instruct:100-instilled-prefs-50ex        500
2 qwen2.5-7b-instruct                                 475
3 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex   245
4 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex    245

> instilled_reports_data %>% count(base_model, sort = TRUE)
# A tibble: 1 × 2
  base_model              n
  <chr>               <int>
1 qwen2.5-7b-instruct  1465

> inst_models_inst_reports <-
+   instilled_reports_data %>%
+   filter(str_detect(model, "instilled"))

> nrow(inst_models_inst_reports)
[1] 500

> inst_models_inst_reports %>% count(model, sort=TRUE) %>% print(n=50)
# A tibble: 1 × 2
  model                                            n
  <chr>                                        <int>
1 qwen2.5-7b-instruct:100-instilled-prefs-50ex   500

> four_fit <-
+   brm(
+     formula = standardized_b ~ standardized_reports,
+     data = inst_models_inst_reports,
+     # data = filter(inst_models .... [TRUNCATED] 
Compiling Stan program...
Start sampling
starting worker pid=45094 on localhost:11654 at 14:48:09.930
starting worker pid=45107 on localhost:11654 at 14:48:10.018
starting worker pid=45120 on localhost:11654 at 14:48:10.091
starting worker pid=45133 on localhost:11654 at 14:48:10.181

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.5e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 1:                0.008 seconds (Sampling)
Chain 1:                0.017 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.6e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 2:                0.009 seconds (Sampling)
Chain 2:                0.019 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.5e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 3:                0.01 seconds (Sampling)
Chain 3:                0.02 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.7e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.023 seconds (Warm-up)
Chain 4:                0.01 seconds (Sampling)
Chain 4:                0.033 seconds (Total)
Chain 4: 
Warning message:
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 

> describe_posterior(four_fit)
Summary of Posterior Distribution 

Parameter            |   Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
------------------------------------------------------------------------------------------------------
(Intercept)          | 2.01e-04 | [-0.09, 0.09] | 50.10% | [-0.10, 0.10] |      100% | 1.000 | 4838.00
standardized_reports |     0.02 | [-0.07, 0.10] | 65.65% | [-0.10, 0.10] |    99.45% | 0.999 | 4645.00

> hdi(four_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.09, 0.09]
standardized_reports | [-0.07, 0.10]

> # mini_fit <-
> #   update(
> #     four_fit,
> #     newdata = filter(inst_models_inst_reports, str_detect(model, "mini"))
> #   )
> # describe_pos .... [TRUNCATED] 

> four_base_fit <-
+   update(
+     four_fit,
+     newdata = base_models_reports,
+     # newdata = filter(base_models_reports, !str_detect(model, " ..." ... [TRUNCATED] 
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.011 seconds (Warm-up)
Chain 1:                0.01 seconds (Sampling)
Chain 1:                0.021 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 2e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.025 seconds (Warm-up)
Chain 2:                0.009 seconds (Sampling)
Chain 2:                0.034 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 2e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 3:                0.01 seconds (Sampling)
Chain 3:                0.02 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 2e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 4:                0.025 seconds (Sampling)
Chain 4:                0.034 seconds (Total)
Chain 4: 

> describe_posterior(four_base_fit)
Summary of Posterior Distribution 

Parameter            |    Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
-------------------------------------------------------------------------------------------------------
(Intercept)          | -8.62e-03 | [-0.10, 0.08] | 57.35% | [-0.10, 0.10] |      100% | 1.000 | 3893.00
standardized_reports |      0.08 | [-0.01, 0.16] | 95.43% | [-0.10, 0.10] |    70.37% | 1.001 | 3684.00

> hdi(four_base_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.10, 0.08]
standardized_reports | [-0.01, 0.17]

> # mini_base_fit <-
> #   update(
> #     four_base_fit,
> #     newdata = filter(base_models_reports, str_detect(model, "mini"))
> #   )
> # describ .... [TRUNCATED] 

> itrained_four_fit <-
+   update(
+     four_fit,
+     newdata = itrained_instilled_reports,
+     # newdata = filter(itrained_instilled_reports, !s .... [TRUNCATED] 
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 4e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.011 seconds (Warm-up)
Chain 1:                0.024 seconds (Sampling)
Chain 1:                0.035 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 2e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.014 seconds (Warm-up)
Chain 2:                0.01 seconds (Sampling)
Chain 2:                0.024 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 3:                0.008 seconds (Sampling)
Chain 3:                0.018 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 2e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.024 seconds (Warm-up)
Chain 4:                0.01 seconds (Sampling)
Chain 4:                0.034 seconds (Total)
Chain 4: 

> describe_posterior(itrained_four_fit)
Summary of Posterior Distribution 

Parameter            |    Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
-------------------------------------------------------------------------------------------------------
(Intercept)          | -2.98e-03 | [-0.09, 0.08] | 53.30% | [-0.10, 0.10] |      100% | 0.999 | 4012.00
standardized_reports |     -0.03 | [-0.12, 0.05] | 76.68% | [-0.10, 0.10] |    95.29% | 1.000 | 3987.00

> hdi(itrained_four_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.09, 0.09]
standardized_reports | [-0.13, 0.05]

> # itrained_mini_fit <-
> #   update(
> #     four_fit,
> #     newdata = filter(itrained_instilled_reports, str_detect(base_model, "mini"))
> #   )
 .... [TRUNCATED] 

> overall_itraining_effect_model <-
+   brm(
+     formula = standardized_b ~ standardized_reports * itrained, # * base_model,
+     data = itraining_ .... [TRUNCATED] 
Compiling Stan program...
Start sampling
starting worker pid=45763 on localhost:11654 at 14:48:33.436
starting worker pid=45776 on localhost:11654 at 14:48:33.525
starting worker pid=45789 on localhost:11654 at 14:48:33.601
starting worker pid=45802 on localhost:11654 at 14:48:33.690

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.057 seconds (Warm-up)
Chain 1:                0.055 seconds (Sampling)
Chain 1:                0.112 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.5e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.044 seconds (Warm-up)
Chain 2:                0.027 seconds (Sampling)
Chain 2:                0.071 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.4e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.029 seconds (Warm-up)
Chain 3:                0.025 seconds (Sampling)
Chain 3:                0.054 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.3e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.026 seconds (Warm-up)
Chain 4:                0.023 seconds (Sampling)
Chain 4:                0.049 seconds (Total)
Chain 4: 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 

> itrain_trends <-
+   emtrends(
+     overall_itraining_effect_model,
+     "itrained",
+     "standardized_reports"
+     # weights = "equal"
+   )

> itrain_cont <- contrast(itrain_trends, method = "revpairwise")

> summary(itrain_cont, infer = c(TRUE, TRUE), level = 0.95)
 contrast     estimate lower.HPD upper.HPD
 TRUE - FALSE  -0.0532    -0.173    0.0769

Point estimate displayed: median 
HPD interval probability: 0.95 

> # Load native preferences.
> native_regression_results <-
+   map_dfr(base_models, function(model) {
+     read_csv(paste0("data/qwen/", model, "_la ..." ... [TRUNCATED] 
Rows: 100 Columns: 6                                                                                   
── Column specification ───────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): b_attr1, b_attr2, b_attr3, b_attr4, b_attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> inst_native_reports <-
+   mean_reports %>%
+   filter(str_detect(model, "instilled")) %>%
+   inner_join(native_regression_results)
Joining with `by = join_by(model, scenario, attr)`

> itrained_inst_native_reports <-
+   mean_reports %>%
+   filter(str_detect(model, "itrained")) %>%
+   inner_join(native_regression_results)
Joining with `by = join_by(model, scenario, attr)`

> native_effect_data <-
+   mean_reports %>%
+   filter(
+     str_detect(model, "100-instilled|itrained-all-100")
+   ) %>%
+   mutate(
+     itraine .... [TRUNCATED] 

> # Test if training improves performance on native preferences.
> native_effect_data %>%
+   group_by(base_model, itrained) %>%
+   summarise(cor = c .... [TRUNCATED] 
`summarise()` has grouped output by 'base_model'. You can override using the `.groups` argument.
# A tibble: 2 × 3
# Groups:   base_model [1]
  base_model          itrained    cor
  <chr>               <lgl>     <dbl>
1 qwen2.5-7b-instruct FALSE    0.0430
2 qwen2.5-7b-instruct TRUE     0.0246

> native_fit <- update(overall_itraining_effect_model, newdata = native_effect_data)
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.029 seconds (Warm-up)
Chain 1:                0.026 seconds (Sampling)
Chain 1:                0.055 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.2e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.032 seconds (Warm-up)
Chain 2:                0.026 seconds (Sampling)
Chain 2:                0.058 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.03 seconds (Warm-up)
Chain 3:                0.026 seconds (Sampling)
Chain 3:                0.056 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 3e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.042 seconds (Warm-up)
Chain 4:                0.028 seconds (Sampling)
Chain 4:                0.07 seconds (Total)
Chain 4: 

> all_native_trends <-
+   emtrends(
+     native_fit,
+     "itrained",
+     "standardized_reports",
+     weights = "equal"
+   )

> native_cont <- contrast(all_native_trends, method = "revpairwise")

> summary(native_cont, infer = c(TRUE, TRUE), level = 0.95)
 contrast     estimate lower.HPD upper.HPD
 TRUE - FALSE  -0.0167    -0.146      0.11

Point estimate displayed: median 
HPD interval probability: 0.95
