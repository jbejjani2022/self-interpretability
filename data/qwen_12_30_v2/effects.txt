12/30 v2
lowered introspection LR further

> source("~/Projects/introspection/self-interpretability/qwen_effects.R", echo = TRUE)

> # `Groundhog` will load the versions of the `R` packages used for the
> # reported analyses. However, it cannot control the version of `R` that you  .... [TRUNCATED] 

> pkgs <- c("tidyverse", "brms", "bayestestR", "emmeans")

> groundhog.library(pkgs, "2025-01-15")
All requested packages are already attached

> # If you don't want to use `groundhog` or have issues with it, comment out the
> # code above and run the following code instead. Note that you will .... [TRUNCATED] 

> base_models <- c(
+   "qwen2.5-7b-instruct"
+ )

> # base_models <- c(
> #   "gpt-4o-mini-2024-07-18",
> #   "gpt-4o-2024-08-06"
> # )
> 
> instilled_parameters <-
+   read_csv("data/instilled_weight ..." ... [TRUNCATED] 
Rows: 1100 Columns: 6                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): attr1, attr2, attr3, attr4, attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> # Load the results of the regressions validating that the preferences were learned.
> instilled_regression_results <-
+   map_dfr(base_models, funct .... [TRUNCATED] 
Rows: 100 Columns: 6                                                                                                                    
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): b_attr1, b_attr2, b_attr3, b_attr4, b_attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> # Verify that the preferences were learned.
> learned_cors <-
+   instilled_regression_results %>%
+   left_join(instilled_parameters) %>%
+   group .... [TRUNCATED] 
Joining with `by = join_by(scenario, attr)`

> learned_cors
# A tibble: 1 × 2
  base_model            cor
  <chr>               <dbl>
1 qwen2.5-7b-instruct 0.850

> # Load and tidy the models' introspective reports.
> weight_reports <-
+   bind_rows(
+     map_dfr(base_models, ~ read_csv(str_glue("data/{.x}_weig ..." ... [TRUNCATED] 
Rows: 915 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 904 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 442 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 465 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 908 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 914 Columns: 18                                                                                                                   
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr  (3): explaining_model, version, scenario
dbl (15): report_attr1, report_attr2, report_attr3, report_attr4, report_attr5, A_attribute_1, A_attribute_2, A_attribute_3, A_attri...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> weight_reports_long <-
+   weight_reports %>%
+   rename(model = explaining_model) %>%
+   select(model, scenario, version, starts_with("report")) % .... [TRUNCATED] 

> mean_reports <-
+   weight_reports_long %>%
+   group_by(model, version, scenario, attr) %>%
+   summarise(mean_report = mean(report)) %>%
+   ungro .... [TRUNCATED] 
`summarise()` has grouped output by 'model', 'version', 'scenario'. You can override using the `.groups` argument.

> # Check the accuracy of model reports (without training).
> instilled_reports_data <-
+   mean_reports %>%
+   filter(version == "instilled_100") %> .... [TRUNCATED] 
Joining with `by = join_by(scenario, attr, base_model)`

> instilled_reports_data %>%
+   count(model, sort = TRUE) %>%
+   print(n = 50)
# A tibble: 4 × 2
  model                                                 n
  <chr>                                             <int>
1 qwen2.5-7b-instruct                                 475
2 qwen2.5-7b-instruct:100-instilled-prefs-50ex        465
3 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex    235
4 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex   230

> instilled_reports_data %>%
+   distinct(model) %>%
+   print(n = 50)
# A tibble: 4 × 1
  model                                            
  <chr>                                            
1 qwen2.5-7b-instruct                              
2 qwen2.5-7b-instruct:100-instilled-prefs-50ex     
3 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex
4 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex 

> inst_models_inst_reports <-
+   instilled_reports_data %>%
+   filter(str_detect(model, "instilled"))

> instilled_reports_data %>% count(model, sort = TRUE) %>% print(n = 50)
# A tibble: 4 × 2
  model                                                 n
  <chr>                                             <int>
1 qwen2.5-7b-instruct                                 475
2 qwen2.5-7b-instruct:100-instilled-prefs-50ex        465
3 qwen2.5-7b-instruct:itrained-last-50-of-100-50ex    235
4 qwen2.5-7b-instruct:itrained-first-50-of-100-50ex   230

> instilled_reports_data %>% count(base_model, sort = TRUE)
# A tibble: 1 × 2
  base_model              n
  <chr>               <int>
1 qwen2.5-7b-instruct  1405

> inst_models_inst_reports <-
+   instilled_reports_data %>%
+   filter(str_detect(model, "instilled"))

> nrow(inst_models_inst_reports)
[1] 465

> inst_models_inst_reports %>% count(model, sort=TRUE) %>% print(n=50)
# A tibble: 1 × 2
  model                                            n
  <chr>                                        <int>
1 qwen2.5-7b-instruct:100-instilled-prefs-50ex   465

> four_fit <-
+   brm(
+     formula = standardized_b ~ standardized_reports,
+     data = inst_models_inst_reports,
+     # data = filter(inst_models .... [TRUNCATED] 
Compiling Stan program...
Start sampling
starting worker pid=40796 on localhost:11505 at 14:33:40.353
starting worker pid=40809 on localhost:11505 at 14:33:40.443
starting worker pid=40822 on localhost:11505 at 14:33:40.531
starting worker pid=40835 on localhost:11505 at 14:33:40.608

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.011 seconds (Warm-up)
Chain 1:                0.01 seconds (Sampling)
Chain 1:                0.021 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.2e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.013 seconds (Warm-up)
Chain 2:                0.008 seconds (Sampling)
Chain 2:                0.021 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.5e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 3:                0.008 seconds (Sampling)
Chain 3:                0.018 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.1e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 4:                0.008 seconds (Sampling)
Chain 4:                0.017 seconds (Total)
Chain 4: 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 

> describe_posterior(four_fit)
Summary of Posterior Distribution 

Parameter            |   Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
------------------------------------------------------------------------------------------------------
(Intercept)          | 2.57e-03 | [-0.09, 0.09] | 51.98% | [-0.10, 0.10] |      100% | 1.000 | 4619.00
standardized_reports |     0.26 | [ 0.18, 0.35] |   100% | [-0.10, 0.10] |        0% | 0.999 | 4705.00

> hdi(four_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.08, 0.09]
standardized_reports | [ 0.18, 0.35]

> # mini_fit <-
> #   update(
> #     four_fit,
> #     newdata = filter(inst_models_inst_reports, str_detect(model, "mini"))
> #   )
> # describe_pos .... [TRUNCATED] 

> four_base_fit <-
+   update(
+     four_fit,
+     newdata = base_models_reports,
+     # newdata = filter(base_models_reports, !str_detect(model, " ..." ... [TRUNCATED] 
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.011 seconds (Warm-up)
Chain 1:                0.01 seconds (Sampling)
Chain 1:                0.021 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 2e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 2:                0.01 seconds (Sampling)
Chain 2:                0.02 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 2e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.021 seconds (Warm-up)
Chain 3:                0.012 seconds (Sampling)
Chain 3:                0.033 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 2e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.009 seconds (Warm-up)
Chain 4:                0.009 seconds (Sampling)
Chain 4:                0.018 seconds (Total)
Chain 4: 

> describe_posterior(four_base_fit)
Summary of Posterior Distribution 

Parameter            |   Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
------------------------------------------------------------------------------------------------------
(Intercept)          | 3.80e-05 | [-0.09, 0.09] | 50.02% | [-0.10, 0.10] |      100% | 1.000 | 4146.00
standardized_reports |     0.02 | [-0.07, 0.11] | 66.77% | [-0.10, 0.10] |    98.45% | 1.000 | 3871.00

> hdi(four_base_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.09, 0.09]
standardized_reports | [-0.07, 0.11]

> # mini_base_fit <-
> #   update(
> #     four_base_fit,
> #     newdata = filter(base_models_reports, str_detect(model, "mini"))
> #   )
> # describ .... [TRUNCATED] 

> itrained_four_fit <-
+   update(
+     four_fit,
+     newdata = itrained_instilled_reports,
+     # newdata = filter(itrained_instilled_reports, !s .... [TRUNCATED] 
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 4e-06 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 1:                0.008 seconds (Sampling)
Chain 1:                0.018 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 2e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.013 seconds (Warm-up)
Chain 2:                0.01 seconds (Sampling)
Chain 2:                0.023 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 2e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 3:                0.009 seconds (Sampling)
Chain 3:                0.019 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.01 seconds (Warm-up)
Chain 4:                0.009 seconds (Sampling)
Chain 4:                0.019 seconds (Total)
Chain 4: 

> describe_posterior(itrained_four_fit)
Summary of Posterior Distribution 

Parameter            |   Median |        95% CI |     pd |          ROPE | % in ROPE |  Rhat |     ESS
------------------------------------------------------------------------------------------------------
(Intercept)          | 1.09e-03 | [-0.07, 0.08] | 50.82% | [-0.10, 0.10] |      100% | 1.001 | 4057.00
standardized_reports |     0.54 | [ 0.46, 0.61] |   100% | [-0.10, 0.10] |        0% | 1.000 | 3935.00

> hdi(itrained_four_fit)
Highest Density Interval 

Parameter            |       95% HDI
------------------------------------
(Intercept)          | [-0.08, 0.07]
standardized_reports | [ 0.46, 0.61]

> # itrained_mini_fit <-
> #   update(
> #     four_fit,
> #     newdata = filter(itrained_instilled_reports, str_detect(base_model, "mini"))
> #   )
 .... [TRUNCATED] 

> overall_itraining_effect_model <-
+   brm(
+     formula = standardized_b ~ standardized_reports * itrained, # * base_model,
+     data = itraining_ .... [TRUNCATED] 
Compiling Stan program...
Start sampling
starting worker pid=41616 on localhost:11505 at 14:34:03.817
starting worker pid=41629 on localhost:11505 at 14:34:03.902
starting worker pid=41642 on localhost:11505 at 14:34:03.979
starting worker pid=41655 on localhost:11505 at 14:34:04.068

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.026 seconds (Warm-up)
Chain 1:                0.038 seconds (Sampling)
Chain 1:                0.064 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 1.4e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.043 seconds (Warm-up)
Chain 2:                0.026 seconds (Sampling)
Chain 2:                0.069 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 1.4e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.028 seconds (Warm-up)
Chain 3:                0.026 seconds (Sampling)
Chain 3:                0.054 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 1.3e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.037 seconds (Warm-up)
Chain 4:                0.028 seconds (Sampling)
Chain 4:                0.065 seconds (Total)
Chain 4: 
Warning message:
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 
Warning message:
package ‘StanHeaders’ was built under R version 4.4.1 

> itrain_trends <-
+   emtrends(
+     overall_itraining_effect_model,
+     "itrained",
+     "standardized_reports"
+     # weights = "equal"
+   )

> itrain_cont <- contrast(itrain_trends, method = "revpairwise")

> summary(itrain_cont, infer = c(TRUE, TRUE), level = 0.95)
 contrast     estimate lower.HPD upper.HPD
 TRUE - FALSE    0.273     0.155     0.391

Point estimate displayed: median 
HPD interval probability: 0.95 

> # Load native preferences.
> native_regression_results <-
+   map_dfr(base_models, function(model) {
+     read_csv(paste0("data/", model, "_latent_ ..." ... [TRUNCATED] 
Rows: 100 Columns: 6                                                                                                                    
── Column specification ────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): scenario
dbl (5): b_attr1, b_attr2, b_attr3, b_attr4, b_attr5

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

> inst_native_reports <-
+   mean_reports %>%
+   filter(str_detect(model, "instilled")) %>%
+   inner_join(native_regression_results)
Joining with `by = join_by(model, scenario, attr)`

> itrained_inst_native_reports <-
+   mean_reports %>%
+   filter(str_detect(model, "itrained")) %>%
+   inner_join(native_regression_results)
Joining with `by = join_by(model, scenario, attr)`

> native_effect_data <-
+   mean_reports %>%
+   filter(
+     str_detect(model, "100-instilled|itrained-all-100")
+   ) %>%
+   mutate(
+     itraine .... [TRUNCATED] 

> # Test if training improves performance on native preferences.
> native_effect_data %>%
+   group_by(base_model, itrained) %>%
+   summarise(cor = c .... [TRUNCATED] 
`summarise()` has grouped output by 'base_model'. You can override using the `.groups` argument.
# A tibble: 2 × 3
# Groups:   base_model [1]
  base_model          itrained   cor
  <chr>               <lgl>    <dbl>
1 qwen2.5-7b-instruct FALSE    0.182
2 qwen2.5-7b-instruct TRUE     0.485

> native_fit <- update(overall_itraining_effect_model, newdata = native_effect_data)
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 1.5e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.028 seconds (Warm-up)
Chain 1:                0.025 seconds (Sampling)
Chain 1:                0.053 seconds (Total)
Chain 1: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 3e-06 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.041 seconds (Warm-up)
Chain 2:                0.024 seconds (Sampling)
Chain 2:                0.065 seconds (Total)
Chain 2: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 3e-06 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.038 seconds (Warm-up)
Chain 3:                0.025 seconds (Sampling)
Chain 3:                0.063 seconds (Total)
Chain 3: 

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 4e-06 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.03 seconds (Warm-up)
Chain 4:                0.024 seconds (Sampling)
Chain 4:                0.054 seconds (Total)
Chain 4: 

> all_native_trends <-
+   emtrends(
+     native_fit,
+     "itrained",
+     "standardized_reports",
+     weights = "equal"
+   )

> native_cont <- contrast(all_native_trends, method = "revpairwise")

> summary(native_cont, infer = c(TRUE, TRUE), level = 0.95)
 contrast     estimate lower.HPD upper.HPD
 TRUE - FALSE    0.304     0.189      0.43

Point estimate displayed: median 
HPD interval probability: 0.95 


Lowering the itraining LR “a little more” didn’t change the instilled introspection gains meaningfully, but it may have slightly reduced the transfer to native prefs (small drop in cor and Δ-slope).
